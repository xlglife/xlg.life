---
{"dg-publish":true,"dg-permalink":"growup100/042-RPA笔记：「生财自动阅读器」升级","permalink":"/growup100/042-RPA笔记：「生财自动阅读器」升级/","tags":["小洛哥成长笔记"],"noteIcon":"1","created":"2024-05-30","updated":"2024-05-30"}
---


> 大家好，我是小洛哥，一个刚刚开始每天写作的新人。
> 
> 日更 100 天，第 42 天。

4 月下旬时做了个「[[5-主题/小洛哥成长笔记/001-040/010-终于动起来了 & 这两天效率低 & 生财自动阅读器2.0\|生财自动阅读器2.0]]」，后来因为 [[5-主题/小洛哥成长笔记/001-040/025-飞书多维表自动化流程次数上限，白嫖字节！\|飞书多维表格达到自动化次数上限]] 的问题，停用了很久。

这不马上 6 月份了，自动化次数上限也该恢复了，这两天捡起来看看能不能优化一下。

## 01 飞书多维表格去重

之前有提到，因为使用网页监听，每次都会采集最近发布的 20 条主题，所以设定了每小时运行一次，然后通过飞书多维表的插件进行去重。

而实际上用起来，飞书多维表内存的东西很多就很卡，而且这个插件的服务也不是很稳定，就导致总会报错。

![](http://img.xlg.life/images%2F2024%2F05%2F29%2F20240529171959-3c4b2a977225d3e170f61bb2bd5f9294.png)

一直在想可以怎么样来解决这个问题。昨天研究了下，终于找到方法了，而且非常优雅且稳定。大体逻辑如下：

1. 首先在多维表格里新建一个视图，筛选昨天到今天发布的主题（一般情况下 20 条的重复不会跨过 2 天）
2. 用「列出记录（视图）」全部获取出来，循环获取到记录 ID 和主题链接
3. 新建两个列表
	- 「ID 的原始列表」，存读取出来的记录 ID
	- 「清洗用的二维列表」，存读取出来的 id 和链接列表，`[记录ID,主题链接]`
4. 将「清洗用的二维列表」用指令「二维列表按列去重」处理，即主题链接相同的列表项，则会被去重
5. 然后循环「清洗用的二维列表」中的记录 ID，在「ID 的原始列表」中逐一删除。这样就获得了被删除掉的记录 ID 列表
6. 最后在飞书多维表里循环逐一删除这些记录 ID 就可以了

过程有点绕，但这个流程不需要打开任何浏览器也不需要获取任何元素。只要网络稳定，就可以稳定运行。还是很赞的。

## 02 飞书自动化改为 Kimi

至于自动化次数上限的问题么...就只好先弃用飞书多维表自己的 AI 字段了，还是祭出国内 AI 大杀器：Kimi！

但这里也有个问题，偶尔 Kimi 会遇到高峰期不可用，而且短时间内对话次数过多，也会导致不可用。

所以本来想的是，每次抓取到 20 条风向标数据后，调整为列表格式，一次性提交给 Kimi，一次性进行多篇风向标的总结和标签匹配。

可试了下发现很不好弄：
1. 是有时风向标的正文内容较多，导致提交给 Kimi 时文本内容很长，虽然 Kimi 支持长文本阅读，但输出结果总是要分 2-3 段，增加了 RPA 的不稳定性
2. AI 给的反馈准确性还是有待提升，不确定是 Kimi 自己的问题还是目前的技术瓶颈，提交 20 条数据，但最终总结有时却会出现只有 17-19 条的情况，多次调整 Prompt 也没有解决

只好弃用批量提交，仍然采取单条提交的情况。虽然这样也会导致稳定性有所下降，但战术上搞不定，咱可以从战略上解决这个问题啊！

1. 仍然采取和上面去重同样的方案，新建筛选视图（筛选规则是总结或标签这个字段为空），原数据（即需要总结的数据）从这里提取。
2. 循环提取到的数据，用写好的 Prompt 模板生成 Prompt，提交给 Kimi，拿到结果，写入原表格（这个比较常见，过程就不赘述了）

这里容易出错的地方在于第 2 点，因为网络不稳定，或者 Kimi 短时间内被限制使用了，就会报错断掉应用。

但灵魂在于第 1 点，如果应用被断掉，这行数据的字段仍然为空，就会在下一次触发时继续交给 Kimi。

因为我设置整个应用仍然是每小时跑 1 次，在每天的高峰时段，哪怕应用挂掉，仍然有机会在当天半夜低峰时段拿到结果！

想想这个套路真 6 啊！哈哈！

## 03 增加中标后的更新

前面在 RPA 里只做了采集、总结、打标的部分，推送到飞书是用的飞书自己的功能。

但每天 100 多条的风向标，除了打标签外，还有哪些方式能精选是高质量的？ 那就是中标了！

所以这次又增加了一个中标的更新。

因为风向标发布，和中标的确认，中间会有时间差。所以在第一次抓取数据时，是无法确认这条会不会中标的。所以我又设计了下面这一套流程：

1. 同样使用网页监听，每小时抓取最近的 20 条中标数据，提取其链接
2. 循环上述链接，与飞书多维表里已存的风向标链接做逐一比对
3. 匹配上的，就增加标注：中标！

这个流程其实比较简单，只需要操作链接这一个字段就可以了。

## 04 独立模块，互不影响

其实也是偶然，等这个写完了发现，整个「生财自动阅读器」已经被我分割成 4 个模块了：

1. 抓取风向标信息并推送到飞书
2. 对飞书已存数据去重
3. 读取飞书数据 Kimi 总结后更新字段
4. 抓取中标信息匹配后更新字段

这 4 个模块我拆成了 4 个流程，使用主流程 +Try 指令，每小时运行一次。

![](http://img.xlg.life/images%2F2024%2F05%2F30%2F20240530233855-88c865d7670616acc74c92478eb18112.png)

4 个独立模块，运行也是互不影响的。
比如 1，只负责数据抓取，不用管重复的问题
比如 2，只要表内有重复就去除，没有就是去重 0 条呗
比如 3，只要有总结/标签字段为空的，就提交给 Kimi，至于数据是什么时候来的不重要
比如 4，抓取到的都是中标的，而这些链接本就应该已经存到表里了，所以一定能匹配上

---

接下来，会继续丢到服务器上运行一段时间，如果有 bug 该修修，过段如果我没有发继续迭代的内容的话，就证明：他很香！